{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cb88022-1bd9-4178-a0ac-084f6082c45c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Import Required Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f0686c7-acd2-44d8-be03-0dc543c6b947",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49b8e845-f429-4e4f-9cc5-4b8b2aaafa38",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__These are specific to using ML with PySpark:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5071ef7-ec9c-4922-9040-d15456cf3fde",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef9cee7a-9c68-48ff-9055-75dc35f3500f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Look at Databrick's DBFS Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dc895c9-640e-483d-8b25-ac2af57c3107",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls(\"/databricks-datasets/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e000761-4917-4361-bd85-bcd11bfe2901",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__The 'Wine quality' dataset is chosen for this demonstration__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54f8e548-ebba-4c6e-86b3-b6ac0376f9bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = \"\"\n",
    "wine_df = spark.read.csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "369c4e7b-f039-459c-aad5-3e2bafdd4bd0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(wine_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8f69496-6646-4266-aa88-af6ccb85b39e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__Each column is already a numeric type (double or integer), which is required for ML tasks__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d94d8e52-0241-47b4-a443-064c5c123cd1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(wine_df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cee90ef-7d9c-40f2-8566-e3db3806962c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__Looking at the statistics and shape of the wine dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6225894-cda4-4a9d-b3e4-e98632e4bab0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a0e0ce9-8fe8-44d2-aa8e-65f7360d245e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__Checking for nulls within the dataset, none are found within the wine dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b6e873b-4832-472a-9ea7-27e320140e47",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "null_counts = wine_df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in wine_df.columns])\n",
    "display(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dba490c-dacc-4fd0-a1af-99e4836211e8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Step 1: Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e46817e7-9641-4497-8771-40ba57bfe218",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__Store all of the columns we will use as features, and exclude the target ('quality')__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfa19434-0cd9-4f28-a0f5-a9609c694cc2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_columns = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70d76ae2-ad48-4dd1-88c6-7ff3175be217",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### VectorAssembler in Spark MLlib\n",
    "\n",
    "The `VectorAssembler` is a transformer in Spark MLlib that combines a list of columns into a single vector column. This transformation is crucial for preparing the dataset for machine learning algorithms, as most of these algorithms expect input features to be consolidated into a single vector.\n",
    "\n",
    "**Key Roles of VectorAssembler:**\n",
    "\n",
    "- **Aggregating Features**: It efficiently aggregates features, enhancing the efficiency of data processing, especially for algorithms designed for parallel computation.\n",
    "\n",
    "- **Meeting Model Expectations**: Spark MLlib models are optimized to work with data presented as a single vector column, making `VectorAssembler` essential for meeting these input requirements.\n",
    "\n",
    "**Creating an Instance of VectorAssembler:**\n",
    "\n",
    "- `inputCols`: Specifies the list of input columns, which in our case are the feature columns of the dataset.\n",
    "\n",
    "- `outputCol`: Names the output column that will contain the transformed vector. We use \"features\" as the name, aligning with standard conventions in Spark ML.\n",
    "\n",
    "**Considerations and Flexibility:**\n",
    "\n",
    "While `VectorAssembler` is widely used in Spark MLlib for its efficiency and alignment with model expectations, it's important to consider the specifics of your data and modeling needs. In some cases, different preprocessing steps might be more appropriate based on the data characteristics or the requirements of the specific machine learning model being used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "466c6161-107d-4511-aabd-7af645bdf119",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "assembler = VectorAssembler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2188ff52-4dd6-4abf-9268-da61f057b43d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__Apply the `VectorAssembler` transformer to the wine dataset__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7e5df3d-66df-4f9a-ae15-3df0afd1ef76",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wine_df_transformed = assembler.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aabe660d-20e9-4fba-89e4-863841c0b93e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__Select only the features and label for the model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4307a0ce-7541-4f5c-afe9-e8676d6adf5a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_data = wine_df_transformed.select()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d32ae49-3fb5-44b8-84a7-48f8710f1ddb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__Splitting the Data into Training and Test Sets__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f82cddae-f7ad-4e33-9784-db180ff66d09",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data, test_data = final_data.randomSplit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31e03568-bced-49b7-bb86-20e3483e7094",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Step 2: Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2752a3e2-1016-4b96-a318-709709c1bb4d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Linear Regression Model\n",
    "Linear regression is one of the simplest and most widely used statistical techniques for predictive modeling. It models the relationship between a dependent variable and one or more independent variables.\n",
    "\n",
    "Here, we are defining a linear regression model with:\n",
    "\n",
    "- `featuresCol`: The name of the features column, which is \"features\" in our case.\n",
    "- `labelCol`: The name of the label column, which is \"quality\", the variable we are trying to predict.\n",
    "\n",
    "We will then fit this model to our training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "709722aa-5191-4a6d-bc68-d0612712fb99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fd360ae-fe8b-4885-8453-ef14aeac12c7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Exploring Different Model Types in Spark MLlib\n",
    "\n",
    "While we focus on linear regression in this lesson Spark MLlib offers a variety of other machine learning models, each suitable for different types of data and tasks:\n",
    "\n",
    "- **Classification Models**: \n",
    "  - *Example - Decision Trees*: Useful for both classification and regression tasks\n",
    "    ```python\n",
    "    from pyspark.ml.classification import DecisionTreeClassifier\n",
    "    dt = DecisionTreeClassifier(featuresCol='features', labelCol='label')\n",
    "    dt_model = dt.fit(train_data)\n",
    "    dt_predictions = dt_model.transform(test_data)\n",
    "    ```\n",
    "\n",
    "- **Clustering Models**: \n",
    "  - *Example - K-Means*: For unsupervised clustering tasks\n",
    "    ```python\n",
    "    from pyspark.ml.clustering import KMeans\n",
    "    kmeans = KMeans().setK(3).setSeed(1)\n",
    "    kmeans_model = kmeans.fit(dataset) # dataset needs to be prepared for clustering\n",
    "    centers = kmeans_model.clusterCenters()\n",
    "    ```\n",
    "\n",
    "- **Recommendation Models**: \n",
    "  - *Example - ALS (Alternating Least Squares)*: Commonly used for building recommendation systems\n",
    "    ```python\n",
    "    from pyspark.ml.recommendation import ALS\n",
    "    als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
    "    als_model = als.fit(training) # training should be a dataset of user-item interactions\n",
    "    als_predictions = als_model.transform(test)\n",
    "    ```\n",
    "\n",
    "Each model type comes with its own set of parameters and considerations, making Spark MLlib a versatile and powerful tool for a wide range of machine learning applications. These examples serve as a starting point for exploring the diversity of models available in Spark MLlib.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eab22bab-9063-4524-8daf-9f9f95308b29",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Step 3: Tuning the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac681823-046e-484b-bff1-5edd08a4453c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Understanding the ParamGridBuilder and Hyperparameter Tuning\n",
    "\n",
    "The `ParamGridBuilder` is a critical tool in Spark MLlib for hyperparameter tuning, allowing us to test different combinations of parameters for our model.\n",
    "\n",
    "**Parameters in this snippet:**\n",
    "\n",
    "- `lr.regParam`: This is the regularization parameter, helping to prevent overfitting. We test values 0.1 and 0.01.\n",
    "- `lr.fitIntercept`: Determines whether an intercept should be used in the linear model. We experiment with `True` and `False`.\n",
    "- `lr.elasticNetParam`: Controls the mix of L1 and L2 regularization, tested with values 0.0, 0.5, and 1.0.\n",
    "\n",
    "**Other Parameters to Consider:**\n",
    "\n",
    "- **Learning Rate**: Often used in iterative algorithms to control the step size at each iteration while moving toward a minimum of a loss function.\n",
    "- **Max Depth (for tree-based models)**: Specifies the maximum depth of the tree.\n",
    "- **Number of Trees (for ensemble models)**: In models like Random Forests, this parameter controls the number of trees in the forest.\n",
    "\n",
    "**Why Hyperparameter Tuning?**\n",
    "\n",
    "Hyperparameter tuning is essential to find the most effective settings for a model, as different parameters can significantly impact model performance and generalizability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55413cec-c807-4511-8afb-27905e7d4d84",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "paramGrid = (\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "852949c1-ef9f-4a04-9928-6673fa927e99",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### CrossValidator for Model Tuning\n",
    "`CrossValidator` in Spark MLlib is used for hyperparameter tuning with cross-validation, which is a method for robustly estimating the performance of a model on unseen data.\n",
    "\n",
    "- `estimator`: This is the machine learning model we want to tune. In our case, it's the linear regression model (`lr`).\n",
    "- `estimatorParamMaps`: This parameter takes the grid of parameters we built with `ParamGridBuilder`.\n",
    "- `evaluator`: This is used to evaluate each model's performance. We're using `RegressionEvaluator` with RMSE as the metric.\n",
    "- `numFolds`: This parameter specifies the number of folds to use for cross-validation. We use 3 folds, meaning the dataset is divided into three parts, and each part is used as a test set once.\n",
    "\n",
    "By using `CrossValidator`, we can ensure that our model tuning is not just tailored to a specific subset of our data, thus improving the model's generalizability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "807366a2-5c7c-4680-ab4b-196a29af3cf4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "crossval = CrossValidator(\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b5367a1-2ac1-45b5-9d59-50e84df70059",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__Fitting the Model with Cross Validation__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77d36c98-c0ab-4eef-bc73-85e31f8065b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cvModel = crossval.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d00cfc55-d091-4512-9196-bb1bd47a25c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Why a Validation Set Is Not Necessary Here\n",
    "\n",
    "For our lesson we are a using `CrossValidator` for hyperparameter tuning meaning that a separate validation set is not strictly necessary because `CrossValidator` inherently performs the function of a validation set:\n",
    "\n",
    "- **Cross-Validation Process**: `CrossValidator` divides the training data into a number of \"folds\". For each combination of parameters in the grid, it trains the model on all but one fold (considered the training set) and evaluates it on the remaining fold (acting as a validation set). This process repeats for each fold, ensuring that each part of the dataset is used for both training and validation. This method provides a robust way to tune parameters while reducing the chance of overfitting.\n",
    "\n",
    "#### Splitting the data for demonstrative purposes\n",
    "\n",
    "```python\n",
    "# Here we split the data into: training, validation, and test sets and then can use the validation set during our hyperparameter testing phase to find best params\n",
    "train_data, temp_data = final_data.randomSplit([0.6, 0.4])\n",
    "validation_data, test_data = temp_data.randomSplit([0.5, 0.5])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9af68f0-a064-4f6d-82f3-4217083a78db",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Step 4: Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76fa7a45-315a-4821-a8cc-b13e3cb945f9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Applying the Tuned Model for Predictions\n",
    "\n",
    "Once we have our model tuned using cross-validation, we apply this optimized model to our test data:\n",
    "\n",
    "- `cvModel.transform(test_data)`: This line uses the `transform` method of our cross-validated model (`cvModel`) to make predictions on the test dataset.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "- **Making Predictions**: The `transform` method applies the best model obtained from cross-validation to the test data, generating predictions based on the learned patterns.\n",
    "\n",
    "- **Evaluating Model Performance**: By applying the model to the test data, which it hasn't seen during training, we can evaluate how well our model generalizes to new data, an essential aspect of machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db670ce3-d206-4c75-ac59-622cfcba0b42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_predictions = cvModel.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f173a70-deba-4d12-b51b-45d0941efffc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Using RegressionEvaluator for Model Evaluation\n",
    "The `RegressionEvaluator` in Spark MLlib is used for evaluating regression models. It computes various statistical metrics to assess the performance of regression models.\n",
    "\n",
    "In this snippet:\n",
    "- `labelCol=\"quality\"`: Specifies the column in the DataFrame which contains the true label values.\n",
    "- `predictionCol=\"prediction\"`: Specifies the column which contains the model's predictions.\n",
    "- `metricName=\"rmse\"`: Indicates that we are using Root Mean Squared Error (RMSE) as our metric for evaluation.\n",
    "\n",
    "By using this evaluator, we can quantify the performance of our model and understand how well it is predicting the wine quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89da0680-7700-4fbb-acb1-9108a297f559",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5429118d-ddef-4ef1-af60-f7a14f98af6e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Understanding Model Performance Metrics in Simple Terms\n",
    "\n",
    "After making predictions using our cross validated model, its important to evaluate its performance using various statistical metrics. This helps us understand the model's accuracy and its ability to generalize to new data. We use the following metrics for evaluation:\n",
    "\n",
    "- **RMSE (Root Mean Squared Error)**: \n",
    "  Imagine you're guessing the weight of a bag of apples. RMSE is like calculating how much you're off on each guess, squaring those differences (to make them positive), taking the average, and then taking the square root of that average. It's a measure of your average error, with larger errors penalized more.\n",
    "\n",
    "- **MSE (Mean Squared Error)**: \n",
    "  Similar to RMSE, but you don't take the square root. It's like guessing the weight of the apples, squaring the errors, and taking the average. The units are squared (e.g., pounds squared if you're measuring weight in pounds), making it harder to interpret directly, but useful for comparing models.\n",
    "\n",
    "\n",
    "- **MAE (Mean Absolute Error)**: \n",
    "  This is straightforward. You're guessing the weight of apples, and MAE is the average of the absolute differences between your guesses and the actual weights. It tells you, on average, how much your guess is likely to be off. It's simpler than RMSE and doesn't heavily penalize larger errors.\n",
    "\n",
    "\n",
    "- **R-squared**: \n",
    "  Think of this like a score in a video game, where 1 (or 100%) is perfect prediction, and 0 is no better than guessing the average every time. It measures how well your guesses match the actual values. The closer to 1, the better your model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caee7570-fc40-4b97-9f27-0542540a0cdf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse = evaluator.evaluate()\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data = {rmse}\")\n",
    "\n",
    "mse = evaluator.evaluate()\n",
    "print(f\"Mean Squared Error (MSE) on test data = {mse}\")\n",
    "\n",
    "mae = evaluator.evaluate()\n",
    "print(f\"Mean Absolute Error (MAE) on test data = {mae}\")\n",
    "\n",
    "r2 = evaluator.evaluate()\n",
    "print(f\"R-squared on test data = {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8db6982-b435-4a4e-9a03-d3387b03a45c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Why MLlib Doesn't Extensively Support Deep Learning\n",
    "\n",
    "Apache Spark's MLlib is a powerful tool for machine learning, particularly in big data contexts. However, it's not primarily focused on deep learning for several reasons:\n",
    "\n",
    "- **Big Data Processing Focus**: Spark, including MLlib, is designed for distributed computing and excels in processing large-scale data. This focus aligns more with traditional machine learning algorithms rather than the computationally intense requirements of deep learning.\n",
    "\n",
    "- **Resource Requirements of Deep Learning**: Deep learning models typically require high computational power, requiring many GPUs. Spark's architecture, while great for distributed data tasks, isn't optimized for the dense computations and GPU utilization deep learning demands.\n",
    "\n",
    "- **Ecosystem Specialization**: Machine learning already features specialized tools. Frameworks like TensorFlow, PyTorch, and Keras are specifically designed for deep learning. This allows Spark MLlib to focus on its strengths in data processing and traditional machine learning.\n",
    "\n",
    "- **Integration Over Reinvention**: Spark integrates with existing deep learning frameworks rather than building its own. This approach allows users to leverage Spark's data processing and feature engineering capabilities alongside specialized deep learning models from frameworks like TensorFlow or Keras.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Coding Demo Practice- Linear Regression ML",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
